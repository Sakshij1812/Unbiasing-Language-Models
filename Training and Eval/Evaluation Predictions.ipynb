{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT_xu5oPLWnG"
   },
   "source": [
    "#Pre-requisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QUGww_seKwDJ"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade git+https://github.com/terrierteam/pyterrier_t5.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vzTNo7hqK2WS"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import itertools\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount(\"/content/drive\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bG6jFLvrK9Dz"
   },
   "outputs": [],
   "source": [
    "#Loading eval input and output datasets\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/Dissertation/Training and Eval/inp.pkl', 'rb') as handle:\n",
    "    inp = pickle.load(handle)\n",
    "\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/Dissertation/Training and Eval/out.pkl', 'rb') as handle:\n",
    "    out = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aFVodgG6LLr7"
   },
   "outputs": [],
   "source": [
    "temp_i = inp\n",
    "temp_o = out\n",
    "\n",
    "len(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "va8Btyy_LQ3T"
   },
   "outputs": [],
   "source": [
    "inp = inp[:600]\n",
    "out = out[:600]\n",
    "\n",
    "len(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSZvFPxFLTph"
   },
   "outputs": [],
   "source": [
    "#Initializing the tokenizer and creating the input ids\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "inp_ids = tokenizer(inp, return_tensors='pt', padding=True).input_ids.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcRmksqUOuLZ"
   },
   "source": [
    "#Defining the model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gocZCfVEO3pU"
   },
   "outputs": [],
   "source": [
    "model_path_baseline=[]\n",
    "model_path_individual = []\n",
    "model_path_all_wgt0=[]\n",
    "model_path_all_wgt1=[]\n",
    "model_path_rel_wgt=[]\n",
    "\n",
    "for i in range(10):\n",
    "  model_path_baseline.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/baseline-'+str(i))\n",
    "  model_path_individual.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/indi-nrwgt1-'+str(i))\n",
    "  model_path_rel_wgt.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/relwgt-nrwgt0-'+str(i))\n",
    "  model_path_all_wgt0.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/batch-allwgt-nrwgt0-'+str(i))\n",
    "  model_path_all_wgt1.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/batch-allwgt-nrwgt1-'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4KUlJnFLcO0"
   },
   "source": [
    "#Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ur4KGyOANgac"
   },
   "outputs": [],
   "source": [
    "result=[]\n",
    "individual_results = []\n",
    "for i in range(10):\n",
    "  #Defining the model\n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_path_individual[i])\n",
    "  device = torch.device(\"cuda\")\n",
    "  model.to(device)\n",
    "\n",
    "  with torch.no_grad():\n",
    "    #saving model predictions in result variable\n",
    "    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n",
    "  #Extracting only probabilities of true and false\n",
    "  result = result[:, 0, (1176, 6136)]\n",
    "  #Converting the probabilites into true or false\n",
    "  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n",
    "#Saving the predictions to google drive\n",
    "with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/indi10.pkl', 'wb') as handle:\n",
    "    pickle.dump(individual_results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DpKR1FNbRKZB"
   },
   "outputs": [],
   "source": [
    "result=[]\n",
    "individual_results = []\n",
    "for i in range(10):\n",
    "  \n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_path_rel_wgt[i])\n",
    "  device = torch.device(\"cuda\")\n",
    "  model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "    #saving model predictions in result variable\n",
    "    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n",
    "  #Extracting only probabilities of true and false\n",
    "  result = result[:, 0, (1176, 6136)]\n",
    "  #COnverting the probabilites into true or false\n",
    "  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n",
    "#Saving the predictions to google drive\n",
    "with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/rel_wgt10.pkl', 'wb') as handle:\n",
    "  pickle.dump(individual_results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hDMGlcmmRKlk"
   },
   "outputs": [],
   "source": [
    "result=[]\n",
    "individual_results = []\n",
    "for i in range(10):\n",
    "  \n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_path_all_wgt0[i])\n",
    "  device = torch.device(\"cuda\")\n",
    "  model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "    #saving model predictions in result variable\n",
    "    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n",
    "  #Extracting only probabilities of true and false\n",
    "  result = result[:, 0, (1176, 6136)]\n",
    "  #COnverting the probabilites into true or false\n",
    "  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n",
    "#Saving the predictions to google drive\n",
    "with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/all_wgt0-10.pkl', 'wb') as handle:\n",
    "  pickle.dump(individual_results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-TActyHRKu9"
   },
   "outputs": [],
   "source": [
    "result=[]\n",
    "individual_results = []\n",
    "for i in range(10):\n",
    "  \n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_path_all_wgt1[i])\n",
    "  device = torch.device(\"cuda\")\n",
    "  model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "    #saving model predictions in result variable\n",
    "    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n",
    "  #Extracting only probabilities of true and false\n",
    "  result = result[:, 0, (1176, 6136)]\n",
    "  #COnverting the probabilites into true or false\n",
    "  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n",
    "#Saving the predictions to google drive\n",
    "with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/all_wgt1-10.pkl', 'wb') as handle:\n",
    "  pickle.dump(individual_results, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4jAJSnraRK89"
   },
   "outputs": [],
   "source": [
    "result=[]\n",
    "individual_results = []\n",
    "for i in range(10):\n",
    "  \n",
    "  model = T5ForConditionalGeneration.from_pretrained(model_path_baseine[i])\n",
    "  device = torch.device(\"cuda\")\n",
    "  model.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "    #saving model predictions in result variable\n",
    "    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n",
    "  #Extracting only probabilities of true and false\n",
    "  result = result[:, 0, (1176, 6136)]\n",
    "  #COnverting the probabilites into true or false\n",
    "  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n",
    "#Saving the predictions to google drive\n",
    "with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/baseline10.pkl', 'wb') as handle:\n",
    "  pickle.dump(individual_results, handle)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Evaluation Predictions.ipynb",
   "provenance": [
    {
     "file_id": "1u0Wyv6CLWPf7BU0mqU_Qv_JTT2NxJJ2Y",
     "timestamp": 1661787256414
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
