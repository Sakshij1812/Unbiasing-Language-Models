{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Evaluation Predictions.ipynb","provenance":[{"file_id":"1u0Wyv6CLWPf7BU0mqU_Qv_JTT2NxJJ2Y","timestamp":1661787256414}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Pre-requisites"],"metadata":{"id":"TT_xu5oPLWnG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"QUGww_seKwDJ"},"outputs":[],"source":["!pip install --upgrade git+https://github.com/terrierteam/pyterrier_t5.git"]},{"cell_type":"code","source":["import pickle\n","from transformers import T5ForConditionalGeneration, T5Tokenizer\n","import itertools\n","import torch\n","torch.cuda.empty_cache()\n","from google.colab import drive\n","import os\n","\n","\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","os.environ['IR_DATASETS_HOME'] = \"/content/drive/MyDrive/Colab Notebooks/Dissertation/ir_datasets\"\n","\n","print(os.getenv('IR_DATASETS_HOME'))"],"metadata":{"id":"vzTNo7hqK2WS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Loading eval input and output datasets\n","with open('/content/drive/MyDrive/Colab Notebooks/Dissertation/inp.pkl', 'rb') as handle:\n","    inp = pickle.load(handle)\n","\n","with open('/content/drive/MyDrive/Colab Notebooks/Dissertation/out.pkl', 'rb') as handle:\n","    out = pickle.load(handle)"],"metadata":{"id":"bG6jFLvrK9Dz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["temp_i = inp\n","temp_o = out\n","\n","len(inp)"],"metadata":{"id":"aFVodgG6LLr7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inp = inp[:600]\n","out = out[:600]\n","\n","len(inp)"],"metadata":{"id":"va8Btyy_LQ3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Initializing the tokenizer and creating the input ids\n","tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n","inp_ids = tokenizer(inp, return_tensors='pt', padding=True).input_ids.cuda()"],"metadata":{"id":"oSZvFPxFLTph"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Defining the model paths"],"metadata":{"id":"WcRmksqUOuLZ"}},{"cell_type":"code","source":["model_path_baseline=[]\n","model_path_individual = []\n","model_path_all_wgt0=[]\n","model_path_all_wgt1=[]\n","model_path_rel_wgt=[]\n","\n","for i in range(10):\n","  model_path_baseline.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/baseline-'+str(i))\n","  model_path_individual.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/indi-nrwgt1-'+str(i))\n","  model_path_rel_wgt.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/relwgt-nrwgt0-'+str(i))\n","  model_path_all_wgt0.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/batch-allwgt-nrwgt0-'+str(i))\n","  model_path_all_wgt1.append('/content/drive/MyDrive/Colab Notebooks/Dissertation/Models/batch-allwgt-nrwgt1-'+str(i))"],"metadata":{"id":"gocZCfVEO3pU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Evaluation"],"metadata":{"id":"v4KUlJnFLcO0"}},{"cell_type":"code","source":["result=[]\n","individual_results = []\n","for i in range(10):\n","  #Defining the model\n","  model = T5ForConditionalGeneration.from_pretrained(model_path_individual[i])\n","  device = torch.device(\"cuda\")\n","  model.to(device)\n","\n","  with torch.no_grad():\n","    #saving model predictions in result variable\n","    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n","  #Extracting only probabilities of true and false\n","  result = result[:, 0, (1176, 6136)]\n","  #COnverting the probabilites into true or false\n","  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n","#Saving the predictions to google drive\n","with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/indi10.pkl', 'wb') as handle:\n","    pickle.dump(individual_results, handle)"],"metadata":{"id":"Ur4KGyOANgac"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result=[]\n","individual_results = []\n","for i in range(10):\n","  \n","  model = T5ForConditionalGeneration.from_pretrained(model_path_rel_wgt[i])\n","  device = torch.device(\"cuda\")\n","  model.to(device)\n","\n","    with torch.no_grad():\n","    #saving model predictions in result variable\n","    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n","  #Extracting only probabilities of true and false\n","  result = result[:, 0, (1176, 6136)]\n","  #COnverting the probabilites into true or false\n","  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n","#Saving the predictions to google drive\n","with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/rel_wgt10.pkl', 'wb') as handle:\n","  pickle.dump(individual_results, handle)"],"metadata":{"id":"DpKR1FNbRKZB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result=[]\n","individual_results = []\n","for i in range(10):\n","  \n","  model = T5ForConditionalGeneration.from_pretrained(model_path_all_wgt0[i])\n","  device = torch.device(\"cuda\")\n","  model.to(device)\n","\n","    with torch.no_grad():\n","    #saving model predictions in result variable\n","    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n","  #Extracting only probabilities of true and false\n","  result = result[:, 0, (1176, 6136)]\n","  #COnverting the probabilites into true or false\n","  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n","#Saving the predictions to google drive\n","with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/all_wgt0-10.pkl', 'wb') as handle:\n","  pickle.dump(individual_results, handle)"],"metadata":{"id":"hDMGlcmmRKlk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result=[]\n","individual_results = []\n","for i in range(10):\n","  \n","  model = T5ForConditionalGeneration.from_pretrained(model_path_all_wgt1[i])\n","  device = torch.device(\"cuda\")\n","  model.to(device)\n","\n","    with torch.no_grad():\n","    #saving model predictions in result variable\n","    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n","  #Extracting only probabilities of true and false\n","  result = result[:, 0, (1176, 6136)]\n","  #COnverting the probabilites into true or false\n","  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n","#Saving the predictions to google drive\n","with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/all_wgt1-10.pkl', 'wb') as handle:\n","  pickle.dump(individual_results, handle)"],"metadata":{"id":"P-TActyHRKu9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["result=[]\n","individual_results = []\n","for i in range(10):\n","  \n","  model = T5ForConditionalGeneration.from_pretrained(model_path_baseine[i])\n","  device = torch.device(\"cuda\")\n","  model.to(device)\n","\n","    with torch.no_grad():\n","    #saving model predictions in result variable\n","    result = model(input_ids = inp_ids, decoder_input_ids=torch.full((len(inp), 1), model.config.decoder_start_token_id, dtype=torch.long, device=device)).logits\n","  #Extracting only probabilities of true and false\n","  result = result[:, 0, (1176, 6136)]\n","  #COnverting the probabilites into true or false\n","  individual_results.append(['true' if row[0] > row[1] else 'false' for row in result])\n","#Saving the predictions to google drive\n","with open(f'/content/drive/MyDrive/Colab Notebooks/Dissertation/Predictions/baseline10.pkl', 'wb') as handle:\n","  pickle.dump(individual_results, handle)"],"metadata":{"id":"4jAJSnraRK89"},"execution_count":null,"outputs":[]}]}